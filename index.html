<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      rel="stylesheet"
      href="https://unpkg.com/@picocss/pico@latest/css/pico.min.css"
    /> 
        <link
      rel="stylesheet"
      href="/css/style.css"
    /> 
    <title>Algoravioli Github/CV</title>
  </head>

  <body>
    <main class="container">
      <hgroup>
        <h1>Christopher Johann Clarke</h1>
        <h2>
          Github:
          <a href="https://github.com/algoravioli"> @algoravioli</a>
        </h2>
      </hgroup>
      <h3>Navigation</h3>
      <a href="#Bio" role="button" class="contrast outline spaced-button">Bio</a>
      <a href="#Education" role="button" class="contrast outline spaced-button">Education</a>
      <a href="#WorkExperience" role="button" class="contrast outline spaced-button"
        >Work Experience</a
      >
      <a href="#Papers" role="button" class="contrast outline spaced-button"
        >Papers/Publications</a
      >
      <a href="#Musictech" role="button" class="contrast outline spaced-button"
        >Work as Music Technologist</a
      >
      <a href="#Awards" role="button" class="contrast outline spaced-button">Awards</a>
      <h1></h1>
      <a id="Bio"></a>
      <h3>A little bit about me.</h3>
      <h6>
        PhD candidate at SUTD (Machine Learning/Artificial Intelligence, Audio
        DSP specialisation) with a passion for reducing resources in Scientific
        Computing.
      </h6>
      <p>
        My research revolves around a general approach for utilising smal neural
        networks (cf. <a href="#Papers">Papers/Publications</a>) to achieve
        greater realtime speeds (less than 5Âµs for inference). This is done in
        hopes of relegating our reliance on extremely power-consuming and
        expensive GPUs to the past. This happens to apply well in the realm of
        audio DSP, as it allows for realtime performance (at audio rates) of
        complex audio processing algorithms.
      </p>
      <p>
        Having been the chief engineer at Speakeasy Studios, with more than 10
        years of experience in audio engineering, I founded OCCD AUDIO, a
        company specialising in audio technologies. It is my current passion
        project, where I design unique analog compressors, EQs, and tube
        microphones, and I work with artists and audio engineers to produce
        analog hardware processors (and sometimes DSP) that are specific to
        their use case.
      </p>
      <p>
        I have also been involved with work as a Music Technologist, with my
        main focus being on generative algorithms and stochastic modelling. Some
        of my past works include: sonification of a neural network for
        performance analysis and AI-enabled/AI-powered audio/music generation,
        real-time deployments of autonomous agents for music generation. My
        latest work: Music Virutal Corpus, is a collection of Machine
        Learning/AI tools for composers, sound designers, and music producers.
        These tools have been abstracted such that only a basic utilitarian
        knowledge of programming is required to use them.
      </p>

      <a id="Education"></a>
      <h3>Education</h3>
      <p></p>
      <details open>
        <summary role="button">Latest</summary>
        <hgroup>
          <h6>PhD. in Machine Learning and Artificial Intelligence</h6>
          <p>2019 - 2023</p>
        </hgroup>
        <hgroup>
          <p>
            Awarded President's Graduate Fellowship (Computing and Information Science
          Disciplines)
            <br />
            Singapore University of Technology and Design, Singapore -
            Department of Science, Math, and Technology
          </p>
        </hgroup>
      </details>
      <details close>
        <summary role="button">Past</summary>
        <hgroup>
          <h6>Master of Music (MMus)</h6>
          <p>2017 - 2019</p>
        </hgroup>
        <p>
          National University of Singapore Yong Siew Toh Conservatory, Singapore
          - Department of Music Composition
        </p>

        <hgroup>
          <h6>Bachelor of Arts (Music) <u>First Class Honours</u></h6>
          <p>2015 - 2017</p>
        </hgroup>
        <p>
          Liverpool Institute for the Performing Arts, Liverpool John Moores
          University, United Kingdom - Department of Music
        </p>

        <hgroup>
          <h6>Diploma in Music and Audio Technology</h6>
          <p>2009 - 2012</p>
        </hgroup>
        <p>
          Singapore Polytechnic, Singapore - Department of Digital Media and
          Infocomm Technology
        </p>

        <hgroup>
          <h6>Certificate in Entrepreneurship In Emerging Economies</h6>
          <p>2020</p>
        </hgroup>
        <p>HarvardX</p>
      </details>

      <a id="WorkExperience"></a>
      <h3>Work Experience</h3>
      <hgroup>
        <h4>OCCD AUDIO</h4>
        <h5>Founder (2018 to 2022)</h5>
        <h6>
          Specialising in audio technologies, a company that: develops hardware
          and software, provides consulting in audio industry, as well as
          recording, mixing, and mastering services.
        </h6>
      </hgroup>
      <hgroup>
        <h4>Blueye Pte Ltd</h4>
        <h5>Tech Lead (2018 to Present)</h5>
        <h6>
          In the field of water technologies and SMART cities, the company
          provides software that validates audiometric readings of leak
          detection, correlation, and other various acoustic and noise
          assessment for water. I am responsible for the development of all the
          algorithms, DSP, Machine Learning, AI, or otherwise.
        </h6>
      </hgroup>
      <hgroup>
        <h4>Adjunct Lecturer</h4>
        <h5>
          Singapore Polytechnic, National University of Singapore,
          Lasalle-College of the Arts, Singapore Institute of Management (2018 -
          Present)
        </h5>
        <h6>
          Acoustical Science, Synthesis, Music and Computing (Music Generation,
          Algorithmic Composition), Desktop Mixing and Production, Appreciation
          of Classical Music, Building Sonic Circuits, Sound and Music Computing
          (Goldsmiths Syllabus)
        </h6>
      </hgroup>
      <hgroup>
        <h4>Speakeasy Studios</h4>
        <h5>Chief Engineer (2010 to 2010)</h5>
        <h6>
          Chief Engineer overseeing all audio and acoustic maintenance,
          development, recording, and commercial output.
        </h6>
      </hgroup>
      <hgroup>
        <h4>Audio Engineer and Music Performer/Composer/Researcher</h4>
        <h5>(2007 to Present)</h5>
        <h6>
          I am one of the few people that can say that I have worked in every
          single segment of the audio chain. Microphone Design, Preamp and
          Processor Design, Converters, Audio Framework, Audio Software; and
          obviously Recording, Mixing, and Mastering. Probably also one of the
          few remaining people that can run a session on a Studer or Otari.
        </h6>
        <p>
          Instruments: Theorbo (Red Dot Baroque, Singapore Symphony Orchestra),
          Mandolin, Guitar (Classical, Electric, and Acoustic) with genres
          spanning from baroque to contemporary classical and experimental.
          Computer Music: Tape Pieces, Sound installations, Algorave (thus the
          name).
        </p>
      </hgroup>

      <a id="Papers"></a>
      <h3>Papers/Publications</h3>
      <h4>Highlighted Paper</h4>
      <hgroup>
        <p>
          RACS '22: International Conference on Research in Adaptive and
          Convergent Systems
        </p>
        <h6>
          <a href="https://dl.acm.org/doi/10.1145/3538641.3561501"
            >Computationally Efficient Physics Approximating Neural Networks for
            Highly Nonlinear Maps</a
          >
        </h6>
        <p>
          Christopher Johann Clarke, Jatin Chowdhury, Cindy Ming Ying Lin, Ivan
          Fu Xing Tan, Prachee Priydarshinee, B.T. Balamurali, Dorien Herremans,
          Jer-Ming Chen
        </p>
      </hgroup>

      <h4>Body of Research</h4>
      <ul>
        <li>
          <hgroup>
            <p>Audio Engineering Society Convention 150</p>
            <h6>
              <a href="https://www.aes.org/e-lib/browse.cfm?elib=21056"
                >Characterising Non-linear Behaviour of Coupling Capacitors
                Through Audio Feature Analysis and Machine Learning</a
              >
            </h6>
            <p>Christopher Johann Clarke, B.T. Balamurali, Jer-Ming Chen</p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>Acoustics Australia / Australian Acoustical Society 49(6)</p>
            <h6>
              <a
                href="https://link.springer.com/article/10.1007/s40857-021-00245-2"
                >Acoustic Effect of Face Mask Design and Material Choice</a
              >
            </h6>
            <p>
              B.T. Balamurali, Tan Enyi, Christopher Johann Clarke, Sim Yuh
              Harn, Jer-Ming Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>European Urology 81:S1250</p>
            <h6>
              <a
                href="https://www.sciencedirect.com/science/article/abs/pii/S0302283822009228?via%3Dihub"
                >Development and Validation of a Deep Learning System for
                Sound-Based Prediction of Urinary Flow</a
              >
            </h6>
            <p>
              Lee H.J., Aslim E., B.T. Balamurali, Ng L.Y.S, Kuo T., Lim K.S,
              Lin C., Clarke C.J, Priyadarshinee P., Jer-Ming Chen, Ng L.G
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>Proceedings of the 19th Sound and Music Computing Conference</p>
            <h6>
              <a href="https://zenodo.org/record/6797472#.Y5lqynZBxhE"
                >Emulating Diode Circuits with Differentiable Wave Digital
                Filters</a
              >
            </h6>
            <p>Jatin Chowdhury and Christopher Johann Clarke</p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>
              2022 IEEE International Conference on Signal Processing and
              Communications (SPCOM)
            </p>
            <h6>
              <a href="https://ieeexplore.ieee.org/document/9840778/"
                >Investigating Synchronized Optical Ballistocardiography vs
                Electrocardiography for Pathological and Healthy Adults</a
              >
            </h6>
            <p>
              Prachee Priyadarshinee, Yixian Tan, Cindy Ming Ying Lin,
              Christopher Johann Clarke, B.T. Balamurali, Enyi Tan, Vern Hsen
              Tan, Siang Chew Chai, Colin Yeo, Jer-Ming Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>The 28th International Congress on Sound and Vibration</p>
            <h6>
              <a
                href="https://www.researchgate.net/publication/365032771_A_REVIEW_OF_AIRBORNE_SOUND_GENERATION_MECHANISMS_OF_A_LIQUID_DROPLET_IMPACT_ON_A_SOLID_SURFACE_THIN_FILM_AND_A_DEEP_POOL"
                >A Review of Airborne Sound Generation Mechanisms of a Liquid
                Droplet Impact on a Solid Surface, Thin Film and a Deep Pool</a
              >
            </h6>
            <p>
              Prachee Priydarshinee, Ashoke Raman, B Harikrishnan, Cindy Ming
              Ying Lin, Christopher Johann Clarke, B.T. Balamurali , Jer-Ming
              Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>The 28th International Congress on Sound and Vibration</p>
            <h6>
              <a
                href="https://www.researchgate.net/publication/365683202_ADDRESSING_MULTI-MODAL_MULTI-MODEL_MULTI-FEATURE_CUES_IN_ALZHEIMER'S_DEMENTIA"
                >Addressing Multi-Modal Multi-Model Multi-Feature Cues in
                Alzheimer's Dementia</a
              >
            </h6>
            <p>
              Christopher Johann Clarke, Jan Melechovsky, Cindy Ming Ying Lin,
              Saumitra Kapoor, Orr Aharonov, Prachee Priydarshinee, B.T.
              Balamurali, Jer-Ming Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>Prceedings of the 24th International Congress on Acoustics</p>
            <h6>
              <a
                href="https://www.researchgate.net/publication/366165772_Performance_Parameter_Survey_of_the_Chinese_Sheng"
                >Performance Parameter Survey of the Chinese Sheng</a
              >
            </h6>
            <p>
              Samuel Goh, Christopher Johann Clarke, Da Yang Tan, Vincent Tan,
              Jer-Ming Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>Prceedings of the 24th International Congress on Acoustics</p>
            <h6>
              <a
                href="https://www.researchgate.net/publication/365034478_Characterization_of_a_Biomechanically_Compliant_Liquid-Metal_Loudspeaker"
                >Characterization of a Biomechanically Compliant Liquid-Metal
                Loudspeaker</a
              >
            </h6>
            <p>
              Prachee Priydarshinee, Cindy Ming Ying Lin, Christopher Johann
              Clarke, B.T. Balamurali, Ivan Fu Xing Tan, Nicole Chian, Kento
              Yamagishi, Michinao Hashimoto, Jer-Ming Chen
            </p>
          </hgroup>
        </li>

        <li>
          <hgroup>
            <p>Prceedings of the 24th International Congress on Acoustics</p>
            <h6>
              <a
                href="https://www.researchgate.net/publication/365034680_Predicting_vocal_tract_geometry_trained_from_acoustic_impedance_of_elliptical_cylinders"
                >Predicting vocal tract geometry trained from acoustic impedance
                of elliptical cylinders</a
              >
            </h6>
            <p>
              Prachee Priydarshinee, Christopher Johann Clarke, B.T. Balamurali,
              Jer-Ming Chen
            </p>
          </hgroup>
        </li>
      </ul>

      <a id="Musictech"></a>
      <h3>Work as Music Technologist</h3>
      <hgroup>
        <h6>
          <a href="https://github.com/algoravioli/pykomposter">Pykomposter</a>
        </h6>
        <p>
          <b>The Meta-Composer: (Composing Composers)</b> This framework
          abstracts the composer one level higher, allowing you do build
          behaviours that compose music for your, instead of directly accessing
          code building music. In essence, broad idea-generating algorithms are
          passed into the system, and the system will/should take care of the
          composition for you.
        </p>
      </hgroup>
      <p>Currently available "Behaviours"</p>
      <ul>
        <li>
          <p>
            <b>IntervalAnalyst</b>: This behaviour looks at the intervals from
            the source set, and produces music based on the intervallic
            structure, and transformations of these structures.
          </p>
        </li>

        <li>
          <p>
            <b>simpleMarkovModeller</b>: An example implementation of a markov
            modeller for pitch, with an output plot of the State Transition
            Matrix.
          </p>
        </li>

        <li>
          <p>
            <b>cubeInCubes</b>: An implementation of the Nomos Alpha system.
          </p>
        </li>

        <li>
          <p>
            <b>finiteStateMachine</b>: A DIY module example of how to assemble a
            Finite State Machine with pykomposter.
          </p>
        </li>

        <li>
          <p>
            <b>roidoRipsis</b>: An implementation of Achorripsis, but with a
            built-in distribution assembler.
          </p>
        </li>
      </ul>

      <h4>Current W.I.P</h4>
      <hgroup>
        <h6>
          Music Virtual Corpus</a>
        </h6>
        <p>
          A set of Machine Learning and A.I algorithms for use in composing music or generating music in realtime.
        </p>
      </hgroup>

      <a id="Awards"></a>
      <h3>Awards</h3>
      <ul>
        <li>Phillip Holt Prize 2017</li>
        <li>Honorable Mention, Point and Shoot 2018 55-Hour Film Competition</li>
        <li>2019 SUTD President's Graduate Fellowship (Computing and Information Science
          Disciplines)</li>
        <li>World Stage Design 2022 (<a href="https://ximi.vercel.app/">XIMI</a>)</li>
      </ul>
    </main>
  </body>
</html>
